import asyncio
import aiohttp
import numpy as np
import matplotlib.pyplot as plt
from matplotlib.animation import FuncAnimation
import json
from threading import Thread
import queue
import time
import argparse

# xAI Grok 4 API (streaming-enabled)
GROK_API_URL = "https://api.x.ai/v1/chat/completions"
API_KEY = "your_xai_api_key_here"  # Swap for real

class FluxInsightCache:
    """Thread-safe cache for Grok insights—reuses to cut calls."""
    def __init__(self):
        self.cache = {}
        self.lock = asyncio.Lock()
        self.last_update = 0
        self.update_interval = 0.5  # Seconds between Grok pings

async def stream_grok_insights(session, flux_data: dict) -> dict:
    """Stream Grok for flux analysis—parse JSON chunks on the fly."""
    headers = {
        "Authorization": f"Bearer {API_KEY}",
        "Content-Type": "application/json"
    }
    # Sample data for speed: downsample grid to 10x10
    sampled_data = {
        "timestamp": flux_data["timestamp"],
        "sampled_grid": [row[::5] for row in flux_data["grid"][::5]],  # Quick slice
        "max_flux": flux_data["max_flux"],
        "avg_flux": flux_data["avg_flux"]
    }
    
    payload = {
        "model": "grok-4",
        "messages": [
            {"role": "system", "content": "Flux mapping pro: Analyze sampled magnetic flux snapshot for anomalies, gradients, predictive flow. Stream JSON: {'anomaly_score': float, 'hotspot_coords': [[x1,y1],[x2,y2]], 'prediction': str}. Keep concise."},
            {"role": "user", "content": json.dumps(sampled_data)}
        ],
        "max_tokens": 150,  # Trim for speed
        "temperature": 0.2,
        "stream": True  # Key: stream chunks
    }
    
    insight = {"anomaly_score": 0, "hotspot_coords": [], "prediction": "Stable flow"}
    buffer = ""
    
    async with session.post(GROK_API_URL, headers=headers, json=payload) as resp:
        if resp.status != 200:
            return insight  # Fallback
        
        async for line in resp.content:
            if line:
                chunk = line.decode().strip()
                if chunk.startswith("data: "):
                    data = chunk[6:].strip()
                    if data == "[DONE]":
                        break
                    buffer += data
                    # Try partial JSON parse (greedy for speed)
                    try:
                        partial = json.loads(buffer)
                        insight.update(partial)
                        buffer = ""  # Reset on success
                    except json.JSONDecodeError:
                        pass  # Buffer more
    
    return insight

def local_fallback(flux_data: dict) -> dict:
    """Quick local anomaly if Grok's pondering."""
    Z = np.array(flux_data["grid"])
    anomaly = np.std(Z) / np.mean(Z) if np.mean(Z) else 0
    return {"anomaly_score": float(anomaly), "hotspot_coords": [], "prediction": "Local est."}

async def grok_heartbeat(cache: FluxInsightCache, flux_queue: queue.Queue):
    """Async pinger: Poll flux, query Grok, cache—runs in bg thread."""
    async with aiohttp.ClientSession() as session:
        while True:
            if not flux_queue.empty():
                flux_data = flux_queue.get()
                now = time.time()  # Sync time for simplicity
                async with cache.lock:
                    if now - cache.last_update > cache.update_interval:
                        try:
                            insight = await stream_grok_insights(session, flux_data)
                        except Exception as e:
                            print(f"Grok hiccup: {e}")  # Graceful
                            insight = local_fallback(flux_data)
                        cache.cache[flux_data["timestamp"]] = insight
                        cache.last_update = now
            await asyncio.sleep(0.01)  # Yield gently

def get_cached_insight(cache: FluxInsightCache, t: float) -> dict:
    """Grab nearest insight—interpolate time-wise."""
    async def _async_get():
        async with cache.lock:
            if not cache.cache:
                return local_fallback({"grid": np.zeros((50,50))})
            # Simple nearest-match (or add linear interp for flux)
            closest_t = min(cache.cache.keys(), key=lambda kt: abs(kt - t))
            return cache.cache.get(closest_t, local_fallback({"grid": np.zeros((50,50))}))
    
    loop = asyncio.new_event_loop()
    asyncio.set_event_loop(loop)
    try:
        return loop.run_until_complete(_async_get())
    finally:
        loop.close()

def simulate_flux_data(t: float) -> dict:
    """Dummy real-time flux gen (replace with sensor read)."""
    x = np.linspace(-5, 5, 50)
    y = np.linspace(-5, 5, 50)
    X, Y = np.meshgrid(x, y)
    Z = np.sin(np.sqrt(X**2 + Y**2) + t) * np.exp(-0.1 * (X**2 + Y**2))
    return {
        "timestamp": t,
        "grid": Z.tolist(),
        "max_flux": float(np.max(Z)),
        "avg_flux": float(np.mean(Z))
    }

def update_flux_map(frame: int, ax, im, flux_queue, cache, scatter=None):
    """Frame updater: Sim fast, cache insights, render zippy."""
    t = frame * 0.016  # ~60fps target
    flux_data = simulate_flux_data(t)
    flux_queue.put(flux_data)  # Feed to heartbeat
    
    start_frame = time.perf_counter()
    insight = get_cached_insight(cache, t)
    frame_time = (time.perf_counter() - start_frame) * 1000  # ms for logging
    
    anomaly_score = insight["anomaly_score"]
    
    Z_new = np.array(flux_data["grid"])
    im.set_array(Z_new)
    ax.set_title(f"Flux Stream (t={t:.2f}s) | Anom: {anomaly_score:.2f} | Pred: {insight['prediction'][:20]}...")
    
    # Hotspots overlay (clear scatter first to avoid ghosts)
    if scatter:
        scatter.remove()
    hs = np.array(insight["hotspot_coords"][:5])  # Cap for perf
    if len(hs) > 0:
        scatter = ax.scatter(hs[:, 0], hs[:, 1], c='red', s=50, marker='x')
    else:
        scatter = None
    
    print(f"Frame {frame}: {frame_time:.1f}ms")  # Live timing peek
    return [im, scatter] if scatter else [im]

# Benchmark harness: Headless timing run
def run_benchmark(num_frames=100):
    flux_queue = queue.Queue()
    cache = FluxInsightCache()
    grok_calls = 0

    def run_heartbeat():
        asyncio.run(grok_heartbeat(cache, flux_queue))

    heartbeat_thread = Thread(target=run_heartbeat, daemon=True)
    heartbeat_thread.start()
    time.sleep(0.1)  # Let it breathe

    frame_times = []
    for frame in range(num_frames):
        t = frame * 0.016
        flux_data = simulate_flux_data(t)
        flux_queue.put(flux_data)
        
        start_frame = time.perf_counter()
        insight = get_cached_insight(cache, t)
        frame_time = (time.perf_counter() - start_frame) * 1000
        frame_times.append(frame_time)
        
        if insight['prediction'] == 'Stable flow':  # Proxy for Grok hit
            grok_calls += 1

    avg_frame = np.mean(frame_times)
    fps = 1000 / avg_frame
    print(f"Benchmark ({num_frames} frames): Avg frame {avg_frame:.1f}ms | Est FPS {fps:.0f} | Grok calls ~{grok_calls}")

# Main launcher
def main(benchmark=False):
    if benchmark:
        run_benchmark()
        return

    flux_queue = queue.Queue()
    cache = FluxInsightCache()

    # Bg thread for async Grok
    def run_heartbeat():
        asyncio.run(grok_heartbeat(cache, flux_queue))

    heartbeat_thread = Thread(target=run_heartbeat, daemon=True)
    heartbeat_thread.start()
    time.sleep(0.1)  # Syncopate

    # Viz setup
    fig, ax = plt.subplots(figsize=(8, 6))
    flux_data = simulate_flux_data(0)
    im = ax.imshow(np.array(flux_data["grid"]), cmap='plasma', extent=[-5,5,-5,5], animated=True)
    scatter = None
    ax.set_xlabel('X')
    ax.set_ylabel('Y')

    ani = FuncAnimation(fig, update_flux_map, fargs=(ax, im, flux_queue, cache, scatter),
                        interval=16, blit=True, cache_frame_data=False)  # 60fps
    plt.colorbar(im, ax=ax, label='Flux Density')
    plt.tight_layout()
    plt.show()

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Low-Latency Flux Mapper")
    parser.add_argument("--benchmark", action="store_true", help="Run headless benchmark")
    args = parser.parse_args()
    main(benchmark=args.benchmark)
